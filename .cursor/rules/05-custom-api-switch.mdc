---
description: 
globs: 
alwaysApply: false
---
# API Integration Guide

This application supports multiple OpenAI-compatible AI providers.

## Supported API Types

- OpenAI API (openai.com)
- Any OpenAI-compatible API endpoints (Azure, self-hosted, etc.)

## Configuration Options

### Using the UI

The application includes a settings panel that allows:
- Switching between API providers
- Entering custom API keys
- Setting custom base URLs
- Adjusting model parameters

### Using Environment Variables

Set up API keys in `.env.local`:
```
OPENAI_API_KEY=your_openai_api_key_here
CUSTOM_API_KEY=your_alternative_api_key_here
CUSTOM_API_BASE_URL=https://your-api-endpoint.com
```

### Modifying Code

If you need to add support for a new API provider that requires custom implementation:

1. Update [app/config.ts](mdc:lite-llm-chatbot/app/config.ts) to include new provider details
2. Modify [app/api/chat/route.ts](mdc:lite-llm-chatbot/app/api/chat/route.ts) to handle the new API:
   - Add authentication
   - Adjust request formatting
   - Handle response parsing differences
3. Update [app/components/ChatSettings.tsx](mdc:lite-llm-chatbot/app/components/ChatSettings.tsx) to include UI options for the new provider

## Model Parameters

The application allows customizing parameters like:
- Temperature
- Maximum tokens
- Top-p sampling
- Frequency penalty
- Presence penalty
